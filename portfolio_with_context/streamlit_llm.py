"""
Powered Land Portfolio Manager - LLM Enhanced
==============================================
Uses Google Sheets as backend + LLM-powered diagnostic chat.

Setup:
1. pip install streamlit pandas plotly google-api-python-client google-auth google-generativeai anthropic PyPDF2 python-docx openpyxl
2. Configure .streamlit/secrets.toml (see GOOGLE_SETUP.md)
3. streamlit run streamlit_llm.py
"""

import streamlit as st
import pandas as pd
import json
import os
import tempfile
import re
from datetime import datetime
from typing import Dict, List, Optional
import plotly.express as px
import plotly.graph_objects as go

# Import modules
from state_analysis import (
    STATE_PROFILES, get_state_profile, generate_state_context_section,
    compare_states, generate_utility_research_queries
)
from document_extraction import (
    process_vdr_upload, extraction_result_to_site_data, parse_conversational_input
)

# PACES GIS Analysis
try:
    from paces_analysis import analyze_paces_image, PACESAnalysisResult
    PACES_AVAILABLE = True
except ImportError:
    PACES_AVAILABLE = False

# Google integration
try:
    from google_integration import (
        GoogleSheetsClient, get_google_client, 
        map_app_to_sheet, map_sheet_to_app,
        GOOGLE_APIS_AVAILABLE
    )
except ImportError:
    GOOGLE_APIS_AVAILABLE = False

# LLM integration
try:
    from llm_integration import PortfolioChat, get_chat_client, refresh_chat_context
    LLM_AVAILABLE = True
except ImportError:
    LLM_AVAILABLE = False

# Program Tracker integration
try:
    from program_management_page import show_program_tracker
    PROGRAM_TRACKER_AVAILABLE = True
except ImportError:
    PROGRAM_TRACKER_AVAILABLE = False

# Document Context integration
try:
    from document_context_page import show_document_context
    DOCUMENT_CONTEXT_AVAILABLE = True
except ImportError:
    DOCUMENT_CONTEXT_AVAILABLE = False


# =============================================================================
# DATA LAYER
# =============================================================================

class DataLayer:
    """Unified data access layer."""
    
    def __init__(self):
        self.use_google = False
        self.google_client = None
        self.local_db = {'sites': {}, 'metadata': {}}
        
        if GOOGLE_APIS_AVAILABLE:
            try:
                self.google_client = GoogleSheetsClient()
                self.use_google = True
            except Exception as e:
                st.sidebar.warning(f"‚ö†Ô∏è Local mode: {str(e)[:40]}")
    
    def get_all_sites(self) -> Dict[str, Dict]:
        if self.use_google:
            sites_list = self.google_client.get_all_sites()
            return {s.get('site_id', f'site_{i}'): map_sheet_to_app(s) for i, s in enumerate(sites_list)}
        return self.local_db.get('sites', {})
    
    def get_site(self, site_id: str) -> Optional[Dict]:
        if self.use_google:
            sheet_site = self.google_client.get_site(site_id)
            return map_sheet_to_app(sheet_site) if sheet_site else None
        return self.local_db.get('sites', {}).get(site_id)
    
    def save_site(self, site_id: str, site_data: Dict) -> bool:
        site_data['site_id'] = site_id
        if self.use_google:
            sheet_data = map_app_to_sheet(site_data)
            sheet_data['site_id'] = site_id
            existing = self.google_client.find_site_row(site_id)
            if existing:
                return self.google_client.update_site(site_id, sheet_data)
            return self.google_client.add_site(sheet_data)
        else:
            site_data['last_updated'] = datetime.now().isoformat()
            self.local_db.setdefault('sites', {})[site_id] = site_data
            return True
    
    def delete_site(self, site_id: str) -> bool:
        if self.use_google:
            return self.google_client.delete_site(site_id)
        if site_id in self.local_db.get('sites', {}):
            del self.local_db['sites'][site_id]
            return True
        return False
    
    def upload_vdr(self, zip_content: bytes, site_id: str, site_name: str) -> Dict:
        if self.use_google:
            return self.google_client.upload_vdr_zip(zip_content, site_id, site_name)
        return {'info': 'Files processed locally only'}
    
    def get_site_files(self, site_id: str, site_name: str) -> List[Dict]:
        if self.use_google:
            folder_id = self.google_client.get_or_create_site_folder(site_id, site_name)
            if folder_id:
                return self.google_client.list_site_files(folder_id)
        return []


# =============================================================================
# SCORING
# =============================================================================

def calculate_site_score(site: Dict, weights: Dict) -> Dict:
    state_profile = get_state_profile(site.get('state', ''))
    state_score = state_profile.overall_score if state_profile else 50
    
    power_score = 0
    study_scores = {'ia_executed': 40, 'fa_executed': 35, 'fs_complete': 28, 'sis_complete': 20, 'sis_in_progress': 12, 'sis_requested': 8, 'not_started': 0}
    power_score += study_scores.get(site.get('study_status', 'not_started'), 0)
    commitment_scores = {'committed': 25, 'verbal': 18, 'engaged': 12, 'initial': 5, 'none': 0}
    power_score += commitment_scores.get(site.get('utility_commitment', 'none'), 0)
    timeline = site.get('power_timeline_months', 60)
    if timeline <= 24: power_score += 20
    elif timeline <= 36: power_score += 15
    elif timeline <= 48: power_score += 10
    power_score = min(power_score + 15, 100)
    
    rel_score = 0
    community_scores = {'champion': 40, 'Strong Support': 35, 'supportive': 30, 'Partial': 20, 'neutral': 15, 'concerns': 5, 'opposition': 0}
    rel_score += community_scores.get(site.get('community_support', 'neutral'), 15)
    political_scores = {'strong': 30, 'Strong Support': 30, 'supportive': 25, 'Partial': 15, 'neutral': 10, 'concerns': 5, 'opposition': 0}
    rel_score += political_scores.get(site.get('political_support', 'neutral'), 10)
    dev_scores = {'extensive': 30, 'High': 30, 'proven': 25, 'Medium': 20, 'limited': 10, 'Low': 5, 'none': 0}
    rel_score += dev_scores.get(site.get('developer_track_record', 'none'), 0)
    rel_score = min(rel_score, 100)
    
    fund_score = 0
    land_scores = {'owned': 35, 'Secured': 35, 'option': 28, 'Development On Partial': 20, 'loi': 18, 'negotiating': 8, 'none': 0}
    fund_score += land_scores.get(site.get('land_control', 'none'), 0)
    capital_scores = {'strong': 35, 'Strong': 35, 'committed': 28, 'Partial': 20, 'available': 18, 'Moderate': 15, 'developing': 8, 'limited': 0}
    fund_score += capital_scores.get(site.get('capital_access', 'limited'), 0)
    fund_score = min(fund_score + 30, 100)
    
    weighted = (
        state_score * weights.get('state', 0.20) +
        power_score * weights.get('power', 0.25) +
        rel_score * weights.get('relationship', 0.25) +
        fund_score * weights.get('fundamentals', 0.30)
    )
    
    return {
        'overall_score': round(weighted, 1),
        'state_score': state_score,
        'power_score': round(power_score, 1),
        'relationship_score': round(rel_score, 1),
        'fundamentals_score': round(fund_score, 1)
    }


def determine_stage(site: Dict) -> str:
    financial = site.get('financial_status', site.get('end_user_status', ''))
    if financial in ['term_sheet', 'loi', 'Strong']: return 'End-User Attached'
    study = site.get('study_status', '')
    if study in ['ia_executed', 'fa_executed']: return 'Fully Entitled'
    commitment = site.get('utility_commitment', '')
    if commitment == 'committed': return 'Utility Commitment'
    if study in ['sis_in_progress', 'sis_complete', 'fs_complete']: return 'Study In Progress'
    land = site.get('land_control', '')
    if land in ['owned', 'option', 'Secured', 'Development On Partial']: return 'Early Real'
    return 'Pre-Development'


# =============================================================================
# MAIN APP
# =============================================================================

def main():
    st.set_page_config(page_title="Powered Land Portfolio Manager", page_icon="‚ö°", layout="wide")
    
    # Initialize
    if 'data' not in st.session_state:
        st.session_state.data = DataLayer()
    if 'weights' not in st.session_state:
        st.session_state.weights = {'state': 0.20, 'power': 0.25, 'relationship': 0.25, 'fundamentals': 0.30}
    if 'chat_messages' not in st.session_state:
        st.session_state.chat_messages = []
    if 'pending_site' not in st.session_state:
        st.session_state.pending_site = None
    
    # Sidebar
    st.sidebar.title("‚ö° Portfolio Manager")
    
    # Connection status
    if st.session_state.data.use_google:
        st.sidebar.success("‚úÖ Google Sheets")
    else:
        st.sidebar.info("üìÅ Local Mode")
    
    # LLM status
    if LLM_AVAILABLE:
        try:
            provider = st.secrets.get("LLM_PROVIDER", "gemini")
            st.sidebar.success(f"ü§ñ {provider.title()} AI")
        except:
            st.sidebar.warning("ü§ñ LLM: No API key")
    else:
        st.sidebar.warning("ü§ñ LLM: Not installed")
    
    page = st.sidebar.radio(
        "Navigation",
        ["üìä Dashboard", "üìà Program Tracker", "üìÑ Document Context", "üí¨ AI Chat", "üó∫Ô∏è PACES Analysis", "üìÅ VDR Upload", "üè≠ Site Database",
         "‚ûï Add/Edit Site", "üèÜ Rankings", "üìç State Analysis", "‚öôÔ∏è Settings"]
    )
    
    if page == "üìä Dashboard": show_dashboard()
    elif page == "üìà Program Tracker": 
        if PROGRAM_TRACKER_AVAILABLE:
            show_program_tracker(st.session_state.data)
        else:
            st.error("Program Tracker module not found")
    elif page == "üìÑ Document Context":
        if DOCUMENT_CONTEXT_AVAILABLE:
            show_document_context(st.session_state.data)
        else:
            st.error("Document Context module not found")
    elif page == "üí¨ AI Chat": show_ai_chat()
    elif page == "üó∫Ô∏è PACES Analysis": show_paces_analysis()
    elif page == "üìÅ VDR Upload": show_vdr_upload()
    elif page == "üè≠ Site Database": show_site_database()
    elif page == "‚ûï Add/Edit Site": show_add_edit_site()
    elif page == "üèÜ Rankings": show_rankings()
    elif page == "üìç State Analysis": show_state_analysis()
    elif page == "‚öôÔ∏è Settings": show_settings()


# =============================================================================
# AI CHAT PAGE
# =============================================================================

def show_ai_chat():
    """LLM-powered diagnostic chat."""
    st.title("üí¨ AI Site Diagnostic Chat")
    
    # Check LLM availability
    if not LLM_AVAILABLE:
        st.error("LLM integration not available. Install: `pip install google-generativeai anthropic`")
        return
    
    # Initialize chat client
    try:
        provider = st.secrets.get("LLM_PROVIDER", "gemini")
        api_key = st.secrets.get(f"{'GEMINI' if provider == 'gemini' else 'ANTHROPIC'}_API_KEY")
        
        if not api_key:
            st.error(f"No API key found. Add {'GEMINI_API_KEY' if provider == 'gemini' else 'ANTHROPIC_API_KEY'} to secrets.toml")
            st.markdown("""
            ```toml
            LLM_PROVIDER = "gemini"  # or "claude"
            GEMINI_API_KEY = "your-key-here"
            ```
            """)
            return
        
        if 'chat_client' not in st.session_state:
            st.session_state.chat_client = PortfolioChat(provider=provider, api_key=api_key)
            # Load portfolio context
            sites = st.session_state.data.get_all_sites()
            st.session_state.chat_client.set_portfolio_context(sites)
            
    except Exception as e:
        st.error(f"Failed to initialize chat: {str(e)}")
        return
    
    # Info box
    with st.expander("‚ÑπÔ∏è How to use AI Chat", expanded=False):
        st.markdown("""
        **This chat understands your full portfolio context.** Describe sites naturally:
        
        *"We're evaluating a 750MW opportunity in Oklahoma, about 5 miles from a 345kV 
        PSO substation. Land is under option, and we've had initial conversations with 
        the utility but haven't filed for queue yet."*
        
        The AI will:
        - Assess the site against your scoring framework
        - Ask targeted diagnostic questions
        - Compare to your existing portfolio
        - Identify critical path items
        - Help you populate the database
        
        **Commands:**
        - "Save this site" - Extract data and add to database
        - "Compare to [site name]" - Compare against existing site
        - "What's missing?" - Identify information gaps
        """)
    
    # Chat interface
    st.markdown("---")
    
    # Display chat history
    for msg in st.session_state.chat_messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
    
    # Chat input
    if prompt := st.chat_input("Describe a site or ask a question..."):
        # Add user message
        st.session_state.chat_messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Get AI response
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                try:
                    response = st.session_state.chat_client.chat(prompt)
                    st.markdown(response)
                    st.session_state.chat_messages.append({"role": "assistant", "content": response})
                    
                    # Check if response suggests saving a site
                    if "save" in prompt.lower() or "add to database" in prompt.lower():
                        # Try to extract site data
                        extracted = extract_site_from_conversation(st.session_state.chat_messages)
                        if extracted:
                            st.session_state.pending_site = extracted
                            
                except Exception as e:
                    st.error(f"Error: {str(e)}")
    
    # Sidebar controls
    st.sidebar.markdown("---")
    st.sidebar.subheader("Chat Controls")
    
    if st.sidebar.button("üîÑ Refresh Context"):
        sites = st.session_state.data.get_all_sites()
        st.session_state.chat_client.set_portfolio_context(sites)
        st.sidebar.success("Context refreshed!")
    
    if st.sidebar.button("üóëÔ∏è Clear History"):
        st.session_state.chat_messages = []
        st.session_state.chat_client.clear_history()
        st.rerun()
    
    # Pending site save
    if st.session_state.pending_site:
        st.markdown("---")
        st.subheader("üìã Save Extracted Site")
        show_site_save_form(st.session_state.pending_site)


def extract_site_from_conversation(messages: List[Dict]) -> Optional[Dict]:
    """Extract site data from conversation history."""
    # Combine all messages
    full_text = " ".join([m["content"] for m in messages])
    
    extracted = {}
    
    # State
    state_match = re.search(r'\b(OK|TX|GA|VA|OH|IN|PA|NV|CA|WY|Oklahoma|Texas|Georgia|Virginia|Ohio|Indiana|Pennsylvania|Nevada|California|Wyoming)\b', full_text, re.IGNORECASE)
    if state_match:
        state = state_match.group(1).upper()
        state_map = {'OKLAHOMA': 'OK', 'TEXAS': 'TX', 'GEORGIA': 'GA', 'VIRGINIA': 'VA', 
                     'OHIO': 'OH', 'INDIANA': 'IN', 'PENNSYLVANIA': 'PA', 'NEVADA': 'NV',
                     'CALIFORNIA': 'CA', 'WYOMING': 'WY'}
        extracted['state'] = state_map.get(state, state)
    
    # MW
    mw_match = re.search(r'(\d+)\s*MW', full_text, re.IGNORECASE)
    if mw_match:
        extracted['target_mw'] = int(mw_match.group(1))
    
    # Utility
    utilities = ['PSO', 'AEP', 'OG&E', 'ONCOR', 'Georgia Power', 'Dominion', 'Duke', 'AES']
    for util in utilities:
        if util.lower() in full_text.lower():
            extracted['utility'] = util
            break
    
    # Study status
    if 'ia executed' in full_text.lower() or 'interconnection agreement' in full_text.lower():
        extracted['study_status'] = 'ia_executed'
    elif 'fa executed' in full_text.lower() or 'facilities agreement' in full_text.lower():
        extracted['study_status'] = 'fa_executed'
    elif 'fs complete' in full_text.lower() or 'facilities study complete' in full_text.lower():
        extracted['study_status'] = 'fs_complete'
    elif 'sis complete' in full_text.lower():
        extracted['study_status'] = 'sis_complete'
    elif 'sis in progress' in full_text.lower() or 'sis underway' in full_text.lower():
        extracted['study_status'] = 'sis_in_progress'
    
    # Land control
    if 'owned' in full_text.lower() or 'own the land' in full_text.lower():
        extracted['land_control'] = 'owned'
    elif 'option' in full_text.lower() or 'under option' in full_text.lower():
        extracted['land_control'] = 'option'
    elif 'loi' in full_text.lower():
        extracted['land_control'] = 'loi'
    
    return extracted if extracted else None


def show_site_save_form(extracted: Dict):
    """Show form to save extracted site data."""
    col1, col2 = st.columns(2)
    
    with col1:
        name = st.text_input("Site Name*", key="save_name")
        state = st.selectbox("State", [''] + list(STATE_PROFILES.keys()),
            index=([''] + list(STATE_PROFILES.keys())).index(extracted.get('state', '')) if extracted.get('state') in STATE_PROFILES else 0,
            key="save_state")
        utility = st.text_input("Utility", value=extracted.get('utility', ''), key="save_util")
        target_mw = st.number_input("Target MW", value=extracted.get('target_mw', 0), key="save_mw")
    
    with col2:
        study_options = ['not_started', 'sis_requested', 'sis_in_progress', 'sis_complete', 'fs_complete', 'fa_executed', 'ia_executed']
        study = st.selectbox("Study Status", study_options,
            index=study_options.index(extracted.get('study_status', 'not_started')) if extracted.get('study_status') in study_options else 0,
            key="save_study")
        land_options = ['none', 'negotiating', 'loi', 'option', 'owned']
        land = st.selectbox("Land Control", land_options,
            index=land_options.index(extracted.get('land_control', 'none')) if extracted.get('land_control') in land_options else 0,
            key="save_land")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("üíæ Save Site", type="primary"):
            if name and state:
                site_id = name.lower().replace(' ', '_').replace('-', '_')
                site_data = {
                    'name': name, 'state': state, 'utility': utility, 'target_mw': target_mw,
                    'study_status': study, 'land_control': land, 'source': 'ai_chat'
                }
                if st.session_state.data.save_site(site_id, site_data):
                    st.success(f"‚úÖ Saved '{name}'!")
                    st.session_state.pending_site = None
                    # Refresh chat context
                    sites = st.session_state.data.get_all_sites()
                    st.session_state.chat_client.set_portfolio_context(sites)
                    st.rerun()
            else:
                st.error("Name and State required")
    with col2:
        if st.button("‚ùå Cancel"):
            st.session_state.pending_site = None
            st.rerun()


# =============================================================================
# PACES ANALYSIS PAGE
# =============================================================================

def show_paces_analysis():
    """PACES GIS image analysis page."""
    st.title("üó∫Ô∏è PACES GIS Analysis")
    
    if not PACES_AVAILABLE:
        st.error("PACES analysis module not available.")
        return
    
    # Check for API
    try:
        provider = st.secrets.get("LLM_PROVIDER", "gemini")
        api_key = st.secrets.get(f"{'GEMINI' if provider == 'gemini' else 'ANTHROPIC'}_API_KEY")
        if not api_key:
            st.error("No LLM API key configured. Add GEMINI_API_KEY or ANTHROPIC_API_KEY to secrets.")
            return
    except Exception as e:
        st.error(f"Configuration error: {e}")
        return
    
    st.markdown("""
    **Upload PACES screenshots or exports** to automatically extract:
    - Parcel size and boundaries
    - Transmission line proximity and voltage
    - Wetlands, floodplains, environmental constraints
    - Adjacent land use and sensitive receptors
    - Infrastructure access (roads, rail, water)
    """)
    
    # File upload
    uploaded_files = st.file_uploader(
        "Upload PACES images",
        type=['png', 'jpg', 'jpeg', 'webp'],
        accept_multiple_files=True,
        help="Upload one or more PACES map exports"
    )
    
    if uploaded_files and st.button("üîç Analyze Images", type="primary"):
        results = []
        
        progress = st.progress(0)
        status = st.empty()
        
        for i, uploaded in enumerate(uploaded_files):
            status.text(f"Analyzing {uploaded.name}...")
            progress.progress((i + 1) / len(uploaded_files))
            
            try:
                result = analyze_paces_image(
                    image_data=uploaded.getvalue(),
                    filename=uploaded.name,
                    provider=provider,
                    api_key=api_key
                )
                results.append((uploaded.name, result))
            except Exception as e:
                st.error(f"Error analyzing {uploaded.name}: {e}")
        
        progress.empty()
        status.empty()
        
        if results:
            st.session_state.paces_results = results
            st.success(f"‚úÖ Analyzed {len(results)} image(s)")
    
    # Display results
    if 'paces_results' in st.session_state and st.session_state.paces_results:
        st.markdown("---")
        
        for filename, result in st.session_state.paces_results:
            st.subheader(f"üìÑ {filename}")
            
            # Suitability badge
            if result.overall_suitability:
                color = {'HIGH': 'üü¢', 'MEDIUM': 'üü°', 'LOW': 'üî¥'}.get(result.overall_suitability.upper(), '‚ö™')
                st.markdown(f"**Suitability:** {color} {result.overall_suitability.upper()} (Confidence: {result.confidence_score:.0%})")
            
            # Key metrics in columns
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Acreage", f"{result.parcel.acreage or 'N/A'}")
            with col2:
                if result.transmission.voltage_kv:
                    st.metric("Transmission", f"{result.transmission.voltage_kv}kV @ {result.transmission.distance_miles or '?'}mi")
                else:
                    st.metric("Transmission", "Not detected")
            with col3:
                wetland_status = "‚ö†Ô∏è Yes" if result.environmental.wetlands_present else "‚úÖ No"
                st.metric("Wetlands", wetland_status)
            with col4:
                flood_status = "‚ö†Ô∏è Yes" if result.environmental.floodplain_100yr else "‚úÖ No"
                st.metric("100yr Flood", flood_status)
            
            # Expandable details
            with st.expander("üìã Full Analysis"):
                tab1, tab2, tab3, tab4, tab5 = st.tabs(["Parcel", "Transmission", "Environmental", "Infrastructure", "Adjacent"])
                
                with tab1:
                    st.write(f"**Acreage:** {result.parcel.acreage}")
                    st.write(f"**Developable:** {result.parcel.developable_acreage}")
                    st.write(f"**Dimensions:** {result.parcel.dimensions}")
                    st.write(f"**County:** {result.parcel.county}")
                    st.write(f"**State:** {result.parcel.state}")
                    st.write(f"**Zoning:** {result.parcel.zoning}")
                    st.write(f"**Current Use:** {result.parcel.current_use}")
                    if result.parcel.notes:
                        st.info(result.parcel.notes)
                
                with tab2:
                    st.write(f"**Voltage:** {result.transmission.voltage_kv} kV")
                    st.write(f"**Distance:** {result.transmission.distance_miles} miles")
                    st.write(f"**Line Name:** {result.transmission.line_name}")
                    st.write(f"**Substation:** {result.transmission.substation_name}")
                    st.write(f"**Substation Distance:** {result.transmission.substation_distance_miles} miles")
                    st.write(f"**Utility:** {result.transmission.owner_utility}")
                    if result.transmission.notes:
                        st.info(result.transmission.notes)
                
                with tab3:
                    st.write(f"**Wetlands Present:** {result.environmental.wetlands_present}")
                    if result.environmental.wetlands_present:
                        st.write(f"  - Coverage: {result.environmental.wetlands_percentage}%")
                        st.write(f"  - Type: {result.environmental.wetlands_type}")
                    st.write(f"**100-Year Floodplain:** {result.environmental.floodplain_100yr}")
                    st.write(f"**500-Year Floodplain:** {result.environmental.floodplain_500yr}")
                    st.write(f"**Protected Lands:** {result.environmental.protected_lands}")
                    st.write(f"**Slope Issues:** {result.environmental.slope_issues}")
                    if result.environmental.notes:
                        st.info(result.environmental.notes)
                
                with tab4:
                    st.write(f"**Road Access:** {result.infrastructure.road_access}")
                    if result.infrastructure.road_access:
                        st.write(f"  - Type: {result.infrastructure.road_type}")
                        st.write(f"  - Name: {result.infrastructure.road_name}")
                    st.write(f"**Rail Access:** {result.infrastructure.rail_access}")
                    if result.infrastructure.rail_access:
                        st.write(f"  - Distance: {result.infrastructure.rail_distance_miles} miles")
                    st.write(f"**Water Nearby:** {result.infrastructure.water_body_nearby}")
                    st.write(f"**Fiber Visible:** {result.infrastructure.fiber_visible}")
                
                with tab5:
                    st.write(f"**North:** {result.adjacent_land_use.north}")
                    st.write(f"**South:** {result.adjacent_land_use.south}")
                    st.write(f"**East:** {result.adjacent_land_use.east}")
                    st.write(f"**West:** {result.adjacent_land_use.west}")
                    st.write(f"**Residential Nearby:** {result.adjacent_land_use.residential_nearby}")
                    if result.adjacent_land_use.residential_nearby:
                        st.write(f"  - Distance: {result.adjacent_land_use.residential_distance_miles} miles")
                    if result.adjacent_land_use.sensitive_receptors:
                        st.warning(f"**Sensitive Receptors:** {', '.join(result.adjacent_land_use.sensitive_receptors)}")
            
            # Constraints and Advantages
            col1, col2 = st.columns(2)
            with col1:
                if result.key_constraints:
                    st.markdown("**‚ö†Ô∏è Key Constraints:**")
                    for c in result.key_constraints:
                        st.write(f"- {c}")
            with col2:
                if result.key_advantages:
                    st.markdown("**‚úÖ Key Advantages:**")
                    for a in result.key_advantages:
                        st.write(f"- {a}")
            
            if result.recommended_next_steps:
                st.markdown("**üìù Recommended Next Steps:**")
                for step in result.recommended_next_steps:
                    st.write(f"1. {step}")
            
            st.markdown("---")
        
        # Save to site form
        st.subheader("üíæ Save to Site Database")
        
        # Use first result as base
        first_result = st.session_state.paces_results[0][1]
        
        col1, col2 = st.columns(2)
        with col1:
            site_name = st.text_input("Site Name*", key="paces_site_name")
            state = st.selectbox("State", [''] + list(STATE_PROFILES.keys()),
                index=([''] + list(STATE_PROFILES.keys())).index(first_result.parcel.state) if first_result.parcel.state in STATE_PROFILES else 0,
                key="paces_state")
            county = st.text_input("County", value=first_result.parcel.county or "", key="paces_county")
        
        with col2:
            acreage = st.number_input("Acreage", value=float(first_result.parcel.acreage or 0), key="paces_acreage")
            transmission_kv = st.number_input("Transmission (kV)", value=int(first_result.transmission.voltage_kv or 0), key="paces_kv")
            transmission_dist = st.number_input("Transmission Distance (mi)", value=float(first_result.transmission.distance_miles or 0), key="paces_dist")
        
        if st.button("üíæ Save Site", type="primary", key="paces_save"):
            if site_name and state:
                site_id = site_name.lower().replace(' ', '_').replace('-', '_')
                
                site_data = {
                    'name': site_name,
                    'state': state,
                    'county': county,
                    'acreage': int(acreage),
                    'source': 'paces_analysis',
                    'paces_data': {
                        'transmission_kv': transmission_kv,
                        'transmission_distance': transmission_dist,
                        'wetlands': first_result.environmental.wetlands_present,
                        'floodplain': first_result.environmental.floodplain_100yr,
                        'suitability': first_result.overall_suitability,
                        'constraints': first_result.key_constraints,
                        'advantages': first_result.key_advantages,
                    }
                }
                
                if st.session_state.data.save_site(site_id, site_data):
                    st.success(f"‚úÖ Saved '{site_name}'!")
                    st.session_state.paces_results = None
                    st.rerun()
            else:
                st.error("Site name and state required")


# =============================================================================
# OTHER PAGES (Same as before, condensed)
# =============================================================================

def show_dashboard():
    st.title("üìä Portfolio Dashboard")
    sites = st.session_state.data.get_all_sites()
    
    if not sites:
        st.info("No sites yet. Use **AI Chat** or **VDR Upload** to add sites.")
        return
    
    col1, col2, col3, col4 = st.columns(4)
    total_mw = sum(s.get('target_mw', 0) for s in sites.values())
    avg_score = sum(calculate_site_score(s, st.session_state.weights)['overall_score'] for s in sites.values()) / len(sites)
    col1.metric("Sites", len(sites))
    col2.metric("Pipeline MW", f"{total_mw:,}")
    col3.metric("Avg Score", f"{avg_score:.1f}")
    col4.metric("States", len(set(s.get('state') for s in sites.values() if s.get('state'))))
    
    st.markdown("---")
    
    data = []
    for site_id, site in sites.items():
        scores = calculate_site_score(site, st.session_state.weights)
        data.append({
            'Site': site.get('name', site_id), 'State': site.get('state', ''),
            'Utility': site.get('utility', ''), 'MW': site.get('target_mw', 0),
            'Stage': determine_stage(site), 'Score': scores['overall_score']
        })
    
    df = pd.DataFrame(sorted(data, key=lambda x: x['Score'], reverse=True))
    st.dataframe(df, column_config={'Score': st.column_config.ProgressColumn(min_value=0, max_value=100)},
                 hide_index=True, use_container_width=True)


def show_vdr_upload():
    st.title("üìÅ VDR Document Upload")
    
    if st.session_state.data.use_google:
        st.success("‚úÖ Files upload to Google Drive")
    
    uploaded = st.file_uploader("Upload VDR (zip)", type=['zip'])
    
    if uploaded and st.button("üîç Process"):
        with st.spinner("Processing..."):
            with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as tmp:
                tmp.write(uploaded.getvalue())
                tmp_path = tmp.name
            try:
                result = process_vdr_upload(tmp_path)
                st.session_state.vdr_result = result
                st.success(f"‚úÖ Processed {result.processed_files} files")
            finally:
                os.unlink(tmp_path)
    
    if 'vdr_result' in st.session_state and st.session_state.vdr_result:
        result = st.session_state.vdr_result
        st.write(f"**State:** {result.state} | **Utility:** {result.utility} | **MW:** {result.target_mw}")
        
        name = st.text_input("Site Name", "VDR Import")
        if st.button("üíæ Save"):
            site_id = name.lower().replace(' ', '_')
            site_data = {'name': name, 'state': result.state, 'utility': result.utility,
                        'target_mw': result.target_mw, 'source': 'vdr_import'}
            if st.session_state.data.save_site(site_id, site_data):
                st.success("Saved!")
                st.session_state.vdr_result = None


def show_site_database():
    st.title("üè≠ Site Database")
    sites = st.session_state.data.get_all_sites()
    
    if not sites:
        st.info("No sites")
        return
    
    data = []
    for site_id, site in sites.items():
        scores = calculate_site_score(site, st.session_state.weights)
        data.append({'id': site_id, 'Site': site.get('name', site_id), 'State': site.get('state', ''),
                     'MW': site.get('target_mw', 0), 'Stage': determine_stage(site), 'Score': scores['overall_score']})
    
    st.dataframe(pd.DataFrame(data)[['Site', 'State', 'MW', 'Stage', 'Score']],
                 column_config={'Score': st.column_config.ProgressColumn(min_value=0, max_value=100)},
                 hide_index=True, use_container_width=True)


def show_add_edit_site():
    st.title("‚ûï Add/Edit Site")
    
    with st.form("site_form"):
        col1, col2, col3 = st.columns(3)
        with col1:
            name = st.text_input("Site Name*")
            state = st.selectbox("State*", [''] + list(STATE_PROFILES.keys()))
            utility = st.text_input("Utility*")
        with col2:
            target_mw = st.number_input("Target MW*", value=0)
            study = st.selectbox("Study Status", ['not_started', 'sis_requested', 'sis_in_progress', 'sis_complete', 'fs_complete', 'fa_executed', 'ia_executed'])
            land = st.selectbox("Land Control", ['none', 'negotiating', 'loi', 'option', 'owned'])
        with col3:
            community = st.selectbox("Community Support", ['opposition', 'concerns', 'neutral', 'supportive', 'champion'])
            capital = st.selectbox("Capital Status", ['limited', 'developing', 'available', 'committed', 'strong'])
        
        if st.form_submit_button("üíæ Save", type="primary"):
            if name and state:
                site_id = name.lower().replace(' ', '_')
                site_data = {'name': name, 'state': state, 'utility': utility, 'target_mw': target_mw,
                            'study_status': study, 'land_control': land, 'community_support': community,
                            'capital_access': capital, 'source': 'manual'}
                if st.session_state.data.save_site(site_id, site_data):
                    st.success(f"Saved '{name}'!")


def show_rankings():
    st.title("üèÜ Rankings")
    sites = st.session_state.data.get_all_sites()
    if not sites:
        st.info("No sites")
        return
    
    rankings = []
    for site_id, site in sites.items():
        scores = calculate_site_score(site, st.session_state.weights)
        rankings.append({'Rank': 0, 'Site': site.get('name', site_id), 'State': site.get('state', ''),
                        'MW': site.get('target_mw', 0), 'Score': scores['overall_score']})
    
    rankings.sort(key=lambda x: x['Score'], reverse=True)
    for i, r in enumerate(rankings):
        r['Rank'] = i + 1
    
    st.dataframe(pd.DataFrame(rankings), column_config={'Score': st.column_config.ProgressColumn(min_value=0, max_value=100)},
                 hide_index=True, use_container_width=True)


def show_state_analysis():
    st.title("üó∫Ô∏è State Analysis")
    selected = st.multiselect("Compare States", list(STATE_PROFILES.keys()), default=['OK', 'TX', 'GA'])
    
    if selected:
        comparisons = compare_states(selected)
        cats = ['Regulatory', 'Transmission', 'Power', 'Water', 'Business', 'Ecosystem']
        fig = go.Figure()
        for s in comparisons:
            vals = [s['regulatory'], s['transmission'], s['power'], s['water'], s['business'], s['ecosystem'], s['regulatory']]
            fig.add_trace(go.Scatterpolar(r=vals, theta=cats + [cats[0]], name=s['name']))
        fig.update_layout(polar=dict(radialaxis=dict(range=[0, 100])), height=500)
        st.plotly_chart(fig, use_container_width=True)


def show_settings():
    st.title("‚öôÔ∏è Settings")
    
    st.subheader("Connection Status")
    col1, col2 = st.columns(2)
    with col1:
        if st.session_state.data.use_google:
            st.success("‚úÖ Google Sheets connected")
        else:
            st.warning("‚ö†Ô∏è Local mode")
    with col2:
        if LLM_AVAILABLE:
            try:
                provider = st.secrets.get("LLM_PROVIDER", "gemini")
                st.success(f"‚úÖ {provider.title()} AI connected")
            except:
                st.warning("‚ö†Ô∏è No LLM API key")
        else:
            st.warning("‚ö†Ô∏è LLM not installed")
    
    st.subheader("Configuration")
    st.markdown("""
    **Required secrets** (`.streamlit/secrets.toml`):
    ```toml
    # Google Sheets
    GOOGLE_SHEET_ID = "your-sheet-id"
    GOOGLE_VDR_FOLDER_ID = "your-folder-id"
    GOOGLE_CREDENTIALS_JSON = '''{"type": "service_account", ...}'''
    
    # LLM (choose one)
    LLM_PROVIDER = "gemini"  # or "claude"
    GEMINI_API_KEY = "your-gemini-key"
    # ANTHROPIC_API_KEY = "your-claude-key"
    ```
    """)
    
    if st.button("üîÑ Refresh"):
        st.session_state.data = DataLayer()
        st.rerun()


if __name__ == "__main__":
    main()
